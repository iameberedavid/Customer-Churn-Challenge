{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFKy32xFcI2L"
   },
   "source": [
    "# CUSTOMER CHURN CHALLENGE ON ZINDI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VqFZjyIcLfd"
   },
   "source": [
    "# Project Description\n",
    "\n",
    "This challenge is for an African telecommunications company that provides customers with airtime and mobile data bundles. The objective of this challenge is to develop a machine learning model to predict the likelihood of each customer “churning”, i.e. becoming inactive and not making any transactions for 90 days.\n",
    "\n",
    "This solution will help this telecom company to better serve their customers by understanding which customers are at risk of leaving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSBaH9zUc9Fs"
   },
   "source": [
    "# Hypothesis\n",
    "\n",
    "Null Hypothesis: There is no relationship between the tenure and the churn of customers.\n",
    "\n",
    "Alternate Hypothesis: There is a relationship between the tenure and the churn of customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Xzzki32dZqZ"
   },
   "source": [
    "# Analytical Questions\n",
    "\n",
    "1. What is the overall churn rate of the telecommunication company?\n",
    "2. What is the churn rate across the various regions?\n",
    "3. What is the churn rate of custmers based on customer regularity?\n",
    "4. What is the churn rate of customers based on their tenure?\n",
    "(Group customers to short-term, mid-term and long term based on their tenure, then check the churn rate)\n",
    "5. What is the churn rate of customers based on the top_up amounts?\n",
    "(Group top_up amount to high, medium and low, then check the churn rate across the groups)\n",
    "6. What is the churn rate of top pack users?\n",
    "7. What is the churn rate based on the data volume?\n",
    "8. What is the churn rate of custmers based on their income frequency?\n",
    "9. What is the churn rate of customers based on their monthly income?\n",
    "(Group monthly income to high-income earners, medium income earners, and low income earners, then check the churn rate across them)\n",
    "10. What is the relationship between the monthly income of customers and the frequency of their recharge (the number of times a customer activated the top pack packages)?\n",
    "11. What is the relationship between the number of times a customer made an income and the number of times a customer activated the top pack?\n",
    "12. What is the churn distribution of customers based on calls to Zone1 and Zone 2?\n",
    "13. What is the churn distribution of customers based international calls, calls to Orange, and calls to Tigo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1JmTFrtRp3bK",
    "outputId": "7829fd69-de5c-4d49-ae8c-c1ef8573ca3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.17.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (3.12.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (2023.6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (4.8.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (23.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "# Installations\n",
    "\n",
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Fy9Saqhfb7sU"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Library for working with Google Drive\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Libraries for visualization\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# Import needed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Library for working with operating system\n",
    "import os\n",
    "\n",
    "# Library for working with Google Drive\n",
    "from google.colab import drive\n",
    "\n",
    "# Libraries for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "import seaborn as sb\n",
    "\n",
    "# Library for testing the hypothesis\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Libraries for features engineering\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Library for splitting the train data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Libraries for balancing the dataset\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Libraries for modelling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Libraries for model evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, precision_recall_curve, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Library for hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Library for saving Machine Learning models\n",
    "import pickle\n",
    "\n",
    "# Library for pushing model to Huggingface\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "# Library to handle warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZcFf0LXRYFwQ"
   },
   "outputs": [],
   "source": [
    "# Set the visualization style\n",
    "\n",
    "sb.set_style('darkgrid')\n",
    "rcParams['figure.figsize'] = 6,4\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWe_XQqLhy1S"
   },
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EPZ-_Legr1Gm"
   },
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "\n",
    "# train = pd.read_csv('Train.csv')\n",
    "# test=  pd.read_csv('Test.csv')\n",
    "# submission_sample = pd.read_csv('SampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "joIy0f3viHg9",
    "outputId": "615d5b35-0d5d-4ad0-a5b0-127b53b57f44"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3NZ1Mh_BiI9I"
   },
   "outputs": [],
   "source": [
    "# Define the directory path to the datasets\n",
    "data_path = '/content/drive/MyDrive/Google Colab/Customer Churn Challenge on Zindi/Data/'\n",
    "\n",
    "# Define the directory path to save images\n",
    "image_path = '/content/drive/MyDrive/Google Colab/Customer Churn Challenge on Zindi/Images'\n",
    "\n",
    "# Define the directory path to save the \"submission_file\"\n",
    "submission_path = '/content/drive/MyDrive/Google Colab/Customer Churn Challenge on Zindi/Submission/'\n",
    "\n",
    "# Define the directory path to save exports\n",
    "export_path = '/content/drive/MyDrive/Google Colab/Customer Churn Challenge on Zindi/Export/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WnLiXfQj5Az2"
   },
   "outputs": [],
   "source": [
    "# Load the datasets from the drive using the data_path\n",
    "\n",
    "train = pd.read_csv(data_path + 'Train.csv')\n",
    "test=  pd.read_csv(data_path + 'Test.csv')\n",
    "submission_sample = pd.read_csv(data_path + 'SampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "id": "zQWcnpyIbfnw",
    "outputId": "b7d8671f-44d9-4eab-8ee9-3194e9c41241"
   },
   "outputs": [],
   "source": [
    "# Display the first five rows of the train dataset\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "id": "7NZgjzq0bfnx",
    "outputId": "83dac535-a5d4-45b5-dd86-b134a3000aeb"
   },
   "outputs": [],
   "source": [
    "# Display the last five rows of the train dataset\n",
    "\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5O93lzi3bfnx",
    "outputId": "27183550-8bbf-4b84-94b1-23d8efc4c7c9"
   },
   "outputs": [],
   "source": [
    "# Obtain the shape of the train data\n",
    "\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HjsBuI5ubfny",
    "outputId": "6ce74c91-884e-4426-e52e-b85122c1c494"
   },
   "outputs": [],
   "source": [
    "# View columns of the train data and their datatypes\n",
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "1hO46jzQbfny",
    "outputId": "255b4cc7-ef27-4ea2-ddc1-afbc63c7ac84"
   },
   "outputs": [],
   "source": [
    "# Display the first five rows of the test dataset\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "PcXnY7ulbfnz",
    "outputId": "2e4b29d6-c5ca-4dcf-9908-8470f893ad18"
   },
   "outputs": [],
   "source": [
    "# Display the last five rows of the test dataset\n",
    "\n",
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0g6j7ioSbfnz",
    "outputId": "a5efd331-dd5b-4cb6-dd32-d6f61f46ca7c"
   },
   "outputs": [],
   "source": [
    "# Obtain the shape of the test dataset\n",
    "\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1u2KWG20bfn0",
    "outputId": "585a7fdb-15fc-4330-f002-82e387066a2d"
   },
   "outputs": [],
   "source": [
    "# View the columns and datatypes of the test dataset\n",
    "\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bdH8_PsOrNgr",
    "outputId": "d3804ade-6bae-4964-b13c-85a625e85cc3"
   },
   "outputs": [],
   "source": [
    "# List all the columns in the train and test dataset\n",
    "\n",
    "train.columns, test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rz_BSfkBrSDi"
   },
   "source": [
    "The train and test datatypes have the same columns with the same datatypes, except that the train dataset has a 'CHURN' column which is absent in the test data. This 'CHURN' column is the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ZCfq7fwubfn0",
    "outputId": "6aabf827-2159-4a08-d712-a69861f60b42"
   },
   "outputs": [],
   "source": [
    "# Display the first five rows of the submission_sample dataset\n",
    "\n",
    "submission_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pIyNHTtabfn1",
    "outputId": "53325a71-e7c6-4023-89b2-79c6da70bacb"
   },
   "outputs": [],
   "source": [
    "# Obtain the shape of the submission_sample dataset\n",
    "\n",
    "submission_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PiYngaJvD5J8"
   },
   "source": [
    "# Visualization of some columns in the *dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 860
    },
    "id": "tvBQP0Rzbfn2",
    "outputId": "c7860985-ccae-4279-837e-152c2c79d193"
   },
   "outputs": [],
   "source": [
    "# Check the levels in the 'REGION' column\n",
    "\n",
    "print(train['REGION'].value_counts())\n",
    "plt.figure(figsize=(10,5))\n",
    "train['REGION'].value_counts(normalize=True).plot(kind='bar')\n",
    "plt.title('Levels in the REGION column')\n",
    "plt.ylabel('counts')\n",
    "plt.xlabel('REGION')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JmwFCnsfuITb"
   },
   "source": [
    "From the plot above, most of the customers are located in Dakar, followed by Thies and Saint-Louis. Kedougou is the region with the least number of customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 752
    },
    "id": "J0-_z-mSbfn2",
    "outputId": "75415039-5027-4cc0-cb4a-54e2e8bea253"
   },
   "outputs": [],
   "source": [
    "# Check the levels in the 'TENURE' column\n",
    "\n",
    "print(train['TENURE'].value_counts())\n",
    "plt.figure(figsize=(10,5))\n",
    "train['TENURE'].value_counts(normalize=True).plot(kind='bar')\n",
    "plt.title('Levels in the TENURE column')\n",
    "plt.ylabel('counts')\n",
    "plt.xlabel('TENURE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sdAXO8cIvRgn"
   },
   "source": [
    "A huge percentage of the customers captured in the train dataset have stayed with the telecommunication company for over 24 months. This implies that the dataset is focused on old customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 752
    },
    "id": "NIhsefA2v3kB",
    "outputId": "2ce5dd52-7845-4578-8803-2975ba343b1f"
   },
   "outputs": [],
   "source": [
    "# Check the levels in the TENURE column of test dataset\n",
    "\n",
    "print(test['TENURE'].value_counts())\n",
    "plt.figure(figsize=(10,5))\n",
    "test['TENURE'].value_counts(normalize=True).plot(kind='bar')\n",
    "plt.title('Levels in the TENURE column of test dataset')\n",
    "plt.ylabel('counts')\n",
    "plt.xlabel('TENURE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HPXzVg-zweLz"
   },
   "source": [
    "Both the train and test datasets focus on old customers, that is, customers that have been with the telecommunication network for over 24 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 546
    },
    "id": "vX2_8obGbfn3",
    "outputId": "a0c6a372-6f5f-4b2d-f45b-569a55d214d0"
   },
   "outputs": [],
   "source": [
    "# Check the levels in the MRG column\n",
    "\n",
    "print(train['MRG'].value_counts())\n",
    "plt.figure(figsize=(10,5))\n",
    "train['MRG'].value_counts(normalize=True).plot(kind='bar')\n",
    "plt.title('Levels in the MRG column')\n",
    "plt.ylabel('counts')\n",
    "plt.xlabel('MRG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c99kyVKhy1c_"
   },
   "source": [
    "The MRG indicates if a client is going. The chart above shows that none of the customers in the train dataset is going."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 546
    },
    "id": "KV4iePNpyJMC",
    "outputId": "8f542c39-7e8f-48bf-c8aa-f821f7d33859"
   },
   "outputs": [],
   "source": [
    "# Check the levels in the MRG column in the test dataset\n",
    "\n",
    "print(test['MRG'].value_counts())\n",
    "plt.figure(figsize=(10,5))\n",
    "test['MRG'].value_counts(normalize=True).plot(kind='bar')\n",
    "plt.title('Levels in the MRG column in the test dataset')\n",
    "plt.ylabel('counts')\n",
    "plt.xlabel('MRG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iDH7l2zHyWfW"
   },
   "source": [
    "The MRG indicates if a client is going. The chart above shows that none of the customers in the test dataset is going."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MXOSvFnWbfn3",
    "outputId": "e228b61e-eec3-4acf-fab3-039516685cbc"
   },
   "outputs": [],
   "source": [
    "# Check the top 40 levels in the TOP_PACK column\n",
    "\n",
    "print(train['TOP_PACK'].value_counts().head(40))\n",
    "plt.figure(figsize=(10,5))\n",
    "train['TOP_PACK'].value_counts(normalize=True).head(40).plot(kind='bar')\n",
    "plt.title('Top 40 Levels in the TOP_PACK column')\n",
    "plt.ylabel('counts')\n",
    "plt.xlabel('TOP_PACK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "id": "5qbExzPDbfn4",
    "outputId": "ba866479-896c-470b-d1dd-1e70b97d0a41"
   },
   "outputs": [],
   "source": [
    "# Check if the predictor class is balanced\n",
    "\n",
    "print(train['CHURN'].value_counts())\n",
    "plt.figure(figsize=(10,5))\n",
    "train['CHURN'].value_counts(normalize=True).plot(kind='bar')\n",
    "plt.title('Levels in the predictor class')\n",
    "plt.ylabel('counts')\n",
    "plt.xlabel('CHURN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "xmeMrQuRbfn5",
    "outputId": "cf99cacd-4c86-40e2-ac7a-66621f8dfe2a"
   },
   "outputs": [],
   "source": [
    "# Check the summary of numerical fields and apply transpose to easily display all the columns\n",
    "\n",
    "summary_statistics = train.select_dtypes(include=['int64', 'float64']).describe().T\n",
    "summary_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "PV2sXr7624GK",
    "outputId": "0e338a1c-9ae1-4e6a-b845-17ca9ee66c9d"
   },
   "outputs": [],
   "source": [
    "# Plot the correlation matrix using heatmap\n",
    "\n",
    "sb.heatmap(summary_statistics.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ZnD-qqxbfn6",
    "outputId": "cb5fe205-c964-456e-8a9a-160a41ee6317"
   },
   "outputs": [],
   "source": [
    "# Check for missing values in train dataset\n",
    "\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WZx70iYUbfn7",
    "outputId": "42ecd952-15ac-4e8c-befd-a3a2ac9ab662"
   },
   "outputs": [],
   "source": [
    "# Check for missing values in test dataset\n",
    "\n",
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nWH8J-eq4xYi"
   },
   "source": [
    "# Hypothesis Testing\n",
    "\n",
    "Null Hypothesis: There is no relationship between the tenure and the churn of customers.\n",
    "\n",
    "Alternate Hypothesis: There is a relationship between the tenure and the churn of customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zcfAbXforVee",
    "outputId": "14d6d683-a7f1-4447-d7ba-95ab0039d1a5"
   },
   "outputs": [],
   "source": [
    "# Define the null hypothesis and alternative hypothesis\n",
    "null_hypothesis = 'There is no relationship between the tenure and churn of customers.'\n",
    "alternative_hypothesis = 'There is a relationship between the tenure and churn of customers.'\n",
    "\n",
    "# Perform the chi-square test\n",
    "observed = pd.crosstab(train['TENURE'], train['CHURN'])\n",
    "chi2, p_value, _, _ = stats.chi2_contingency(observed)\n",
    "\n",
    "# Set the significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Print the test results\n",
    "print('Null Hypothesis:', null_hypothesis)\n",
    "print('Alternative Hypothesis:', alternative_hypothesis)\n",
    "print('Significance Level (alpha):', alpha)\n",
    "print('Chi-square statistic:', chi2)\n",
    "print('P-value:', p_value)\n",
    "\n",
    "# Compare the p-value with the significance level\n",
    "if p_value < alpha:\n",
    "\n",
    "    print(f'Result: Reject the null hypothesis.', alternative_hypothesis)\n",
    "else:\n",
    "    print(f'Result: Fail to reject the null hypothesis.', null_hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktVaXlgx0iIW"
   },
   "source": [
    " The P-value of 0.0 suggests a strong evidence against the null hypothesis, indicating a statistically significant result. There is a strong relationship between customer tenure and customer churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLcfNIYE41Qq"
   },
   "source": [
    "# Answering Analytical Questions\n",
    "\n",
    "## Questions\n",
    "\n",
    "1. What is the overall churn rate of the telecommunication company?\n",
    "2. What is the churn rate across the various regions?\n",
    "3. What is the churn rate of custmers based on customer regularity?\n",
    "4. What is the churn rate of customers based on their tenure?\n",
    "(Group customers to short-term, mid-term and long term based on their tenure, then check the churn rate)\n",
    "5. What is the churn rate of customers based on the top_up amounts?\n",
    "(Group top_up amount to high, medium and low, then check the churn rate across the groups)\n",
    "6. What is the churn rate of top pack users?\n",
    "7. What is the churn rate based on the data volume?\n",
    "8. What is the churn rate of custmers based on their income frequency?\n",
    "9. What is the churn rate of customers based on their monthly income?\n",
    "(Group monthly income to high-income earners, medium income earners, and low income earners, then check the churn rate across them)\n",
    "10. What is the relationship between the monthly income of customers and the frequency of their recharge (the number of times a customer activated the top pack packages)?\n",
    "11. What is the relationship between the number of times a customer made an income and the number of times a customer activated the top pack?\n",
    "12. What is the churn distribution of customers based on calls to Zone1 and Zone 2?\n",
    "13. What is the churn distribution of customers based international calls, calls to Orange, and calls to Tigo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSfgffrtx_HU"
   },
   "source": [
    "Question 1: What is the overall churn rate of the telecommunication company?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "id": "9_2Dtzs6x94t",
    "outputId": "46791a95-1651-4ace-c569-3e8066cf1f4f"
   },
   "outputs": [],
   "source": [
    "# Calculate the churn rate\n",
    "total_customers = len(train)\n",
    "churned_customers = train['CHURN'].sum()\n",
    "churn_rate = (churned_customers / total_customers) * 100\n",
    "\n",
    "# Display the churn rate\n",
    "print('Total Customers:', total_customers)\n",
    "print('Churned Customers:', churned_customers)\n",
    "print(f'Churn Rate: {churn_rate.round(1)}%')\n",
    "\n",
    "# Plot the churn rate\n",
    "# plt.figure(figsize=(6, 4))\n",
    "plt.bar(['Churned', 'Not Churned'], [churn_rate, 100-churn_rate])\n",
    "plt.title('Overall Churn Rate Of The Telecommunication Network')\n",
    "plt.xlabel('Churn Status')\n",
    "plt.ylabel('Percentage')\n",
    "plt.ylim([0, 100])\n",
    "\n",
    "# Save the plot into the drive through the image_path\n",
    "file_name = 'Overall Churn Rate Of The Telecommunication Network.png' # Specify the file name and extension\n",
    "file_path = os.path.join(image_path, file_name) # Combine the file name with the image_path\n",
    "plt.savefig(file_path)\n",
    "\n",
    "# Display the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04gOYIJ07wia"
   },
   "source": [
    "201,993 customers have churned out of 1,077,024 customers in the train dataset. This represents an 18.8% churn rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3E6bK8k1yeBO"
   },
   "source": [
    "Question 2: What is the churn rate across the various regions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V5yBQ-JgyhKT",
    "outputId": "46927173-eb63-4c4f-d1ec-ec53e9625667"
   },
   "outputs": [],
   "source": [
    "# Identify the regions\n",
    "\n",
    "regions = train['REGION'].unique()\n",
    "regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FrGH-5SrOURl"
   },
   "source": [
    "Notice that the 'REGION' column above has missing values. The percentage of these rows with missing values will be evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mcAOFcG0Emtf",
    "outputId": "db7c1c1a-18d2-44b1-c80b-40000a6304d4"
   },
   "outputs": [],
   "source": [
    "# Calculate the total number of rows with missing values in the 'REGION' column\n",
    "missing_rows = train['REGION'].isnull().sum()\n",
    "\n",
    "# Calculate the total number of rows in the DataFrame\n",
    "total_rows = len(train)\n",
    "\n",
    "# Calculate the percentage of rows with missing values in the 'REGION' column\n",
    "percentage_missing = (missing_rows / total_rows) * 100\n",
    "\n",
    "print(f\"The percentage of rows with missing values in 'REGION' column is: {percentage_missing:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7PD7WA2EjKG"
   },
   "source": [
    "39.4 % of the rows in the 'REGION\" column have missing values. These rows will be dropped in order to properly analyze the rest of the rows. A new copy of the train dataset will be created for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "b9nMK8vuLB17",
    "outputId": "e908b253-21dd-4f89-a89b-4c9e102a4bb3"
   },
   "outputs": [],
   "source": [
    "# Create a copy of the train dataset\n",
    "train_df = train.copy()\n",
    "\n",
    "# Drop rows with missing values in the 'REGION' column\n",
    "train_df = train_df.dropna(subset=['REGION'])\n",
    "\n",
    "# Identify the regions and the customers per region\n",
    "regions = train_df['REGION'].unique()\n",
    "customers_per_region = train_df['REGION'].value_counts()\n",
    "percentage_of_customers_per_region = ((customers_per_region / customers_per_region.sum()) * 100).round(1)\n",
    "\n",
    "# Initialize lists to store data for all regions\n",
    "churned_customers_per_region = []\n",
    "churn_rate_per_region = []\n",
    "\n",
    "# Function to calculate the churn rate of different regions\n",
    "for region in regions:\n",
    "    region_df = train_df[train_df['REGION'] == region]\n",
    "    churned_customers = region_df['CHURN'].sum()\n",
    "    total_customers = len(region_df)\n",
    "\n",
    "    if total_customers > 0:\n",
    "        churn_rate = (churned_customers / total_customers) * 100\n",
    "    else:\n",
    "        churn_rate = 0.0\n",
    "\n",
    "    churn_rate = churn_rate.round(1)\n",
    "\n",
    "    churned_customers_per_region.append(churned_customers)\n",
    "    churn_rate_per_region.append(churn_rate)\n",
    "\n",
    "# Create a dictionary to store the region and churn data\n",
    "churn_rate_by_region = {\n",
    "    'REGION': regions,\n",
    "    'CUSTOMERS PER REGION': customers_per_region,\n",
    "    'PERCENTAGE OF CUSTOMERS': percentage_of_customers_per_region,\n",
    "    'CHURNED CUSTOMERS PER REGION': churned_customers_per_region,\n",
    "    'CHURN RATE (%)': churn_rate_per_region\n",
    "}\n",
    "\n",
    "# Display the region and churn data as a DataFrame\n",
    "churn_rate_by_region_df = pd.DataFrame(churn_rate_by_region).reset_index(drop=True)\n",
    "churn_rate_by_region_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5dmuU3-WYhA"
   },
   "source": [
    "The DataFrame above shows the number of customers in each region, the percentage of customers in each region, the number of customers that churned, and the churn rate of each region. The highest churn rate is observed in Sedhiou Region with a churn rate of 5.41% and Kedougou region with a churn rate of 4.09%. Also observe that these regions have the lowest number (and percentage) of customers. This suggests that the telecommunication network should intensify customer retention policies in these regions. The region with a very low churn rate is Kaffrine region with a churn rate of 0.7%. Dakar region has the highest number (and percentage) of customers with a moderate churn rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "k3DZTSG2kX37",
    "outputId": "e5154048-0944-4316-d5f6-5b82578e5080"
   },
   "outputs": [],
   "source": [
    "# Plot the churn rate per region\n",
    "# plt.figure(figsize=(6, 4))\n",
    "plt.bar(churn_rate_by_region_df.index, churn_rate_by_region_df['CHURN RATE (%)'], tick_label=churn_rate_by_region_df['REGION'])\n",
    "plt.title('Churn Rate by Region')\n",
    "plt.xlabel('Region')\n",
    "plt.ylabel('Churn Rate (%)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot into the drive through the image_path\n",
    "file_name = 'Churn Rate by Region.png'\n",
    "file_path = os.path.join(image_path, file_name)\n",
    "plt.savefig(file_path)\n",
    "\n",
    "# Show the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SoTsPrGvWHIM"
   },
   "source": [
    "As shown above, Sedhiou region has the highest churn rate followed by Kedougou region, while Kaffrine region has the lowest churn rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r5fw2eIpyhyD"
   },
   "source": [
    "Question 3: What is the churn rate of customers based on customer regularity?\n",
    "\n",
    "Regularity refers to the number of times a customer is active for 90 days. The most active and least active customers will be determined first, and checked for churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pDnQLA8hylmN",
    "outputId": "f82a4680-516c-452f-8113-22c7bed78570"
   },
   "outputs": [],
   "source": [
    "# Find the highest and lowest values in the \"REGULARITY\" column\n",
    "highest_regularity = train['REGULARITY'].max()\n",
    "lowest_regularity = train['REGULARITY'].min()\n",
    "\n",
    "# Find the user ID of the most active customer and least active customer\n",
    "most_active = train[train['REGULARITY'] == highest_regularity]['user_id'].values[0]\n",
    "least_active = train[train['REGULARITY'] == lowest_regularity]['user_id'].values[0]\n",
    "\n",
    "# Check if the most active customer and least active customer churned\n",
    "churned_most_active = train[train['user_id'] == most_active]['CHURN'].values[0]\n",
    "churned_least_active = train[train['user_id'] == least_active]['CHURN'].values[0]\n",
    "\n",
    "# Print the results\n",
    "print(f\"Customer {most_active} had the highest regularity of {highest_regularity} and {'churned' if churned_most_active == 1 else 'did not churn'}.\")\n",
    "print(f\"Customer {least_active} had the lowest regularity of {lowest_regularity} and {'churned' if churned_least_active == 1 else 'did not churn'}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ln9t8Waze7G2"
   },
   "source": [
    "As shown above. the most active and least active customers did not churn.\n",
    "\n",
    "Next, the usage activity of the customers will be used to group them into Low-Usage Customers, Medium-Usage Customers, and High-Usage Customers. These groups of customers will then be checked for churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "Q1hoxwwWgW83",
    "outputId": "e1894a70-477d-42f6-f8a2-0dccd042cdb0"
   },
   "outputs": [],
   "source": [
    "# Define the usage groups and corresponding labels\n",
    "bins = [0, 20, 40, float('inf')]\n",
    "labels = ['Low-Usage Customers', 'Medium-Usage Customers', 'High-Usage Customers']\n",
    "\n",
    "# Create a new column 'usage_group' to store the usage group labels\n",
    "train['usage_group'] = pd.cut(train['REGULARITY'], bins=bins, labels=labels)\n",
    "\n",
    "# Calculate the churn rate, the number of customers and the percentage of customers in each group\n",
    "churn_rate_by_group = train.groupby('usage_group')['CHURN'].mean()\n",
    "customers_per_group = train['usage_group'].value_counts()\n",
    "percentage_customers_per_group = round((customers_per_group / customers_per_group.sum()) * 100,1)\n",
    "\n",
    "# Remove the 'usage_group' column\n",
    "train.drop('usage_group', axis=1, inplace=True)\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "usage_group_data = pd.DataFrame({'Number of Customers': customers_per_group, 'Percentage of Customers in Group(%)': percentage_customers_per_group, 'Churn Rate (%)': churn_rate_by_group})\n",
    "\n",
    "# Display the DataFrame\n",
    "usage_group_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HB0m7TLP-tIy"
   },
   "source": [
    "As shown in the DataFrame above, there are more Low-Usage Customers (499,031), and this group of customers have the highest churn rate (0.379327). While High-Usage Customers (375,819) have the lowest churn rate (0.009004). This suggests that customer retention policies should be targeted at the Low-Usage Customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "gYDATowK9thn",
    "outputId": "8bd1c114-6a1d-4de9-92a7-48c3120b22a3"
   },
   "outputs": [],
   "source": [
    "# Plot the churn rate across the usage groups\n",
    "# plt.figure(figsize=(6, 4))\n",
    "churn_rate_by_group.plot(kind='bar', color='skyblue', alpha=0.7)\n",
    "plt.title('Churn Rate Across Usage Groups Based On Regularity')\n",
    "plt.xlabel('Usage Groups Based on Regularity')\n",
    "plt.ylabel('Churn Rate')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot into the drive through the image_path\n",
    "file_name = 'Churn Rate Across Usage Groups Based On Regularity.png'\n",
    "file_path = os.path.join(image_path, file_name)\n",
    "plt.savefig(file_path)\n",
    "\n",
    "# Show the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ShrBAr19cjj"
   },
   "source": [
    "The chart above illustrates that Low-Usage Customers have the highest churn rate while High-Usage Customers have the lowest churn rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zWwtOtgtyl4C"
   },
   "source": [
    "Question 4: What is the churn rate of customers based on their tenure?\n",
    "A customer's tenure refers to the customer's duration in the network. The unique tenures are identified below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jlSbpvSnysdi",
    "outputId": "0550383c-0a2b-43ae-defe-34d689e99c9a"
   },
   "outputs": [],
   "source": [
    "# Identify the unique tenures in the 'TENURE' group\n",
    "\n",
    "train['TENURE'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ah2l73CPB6kd"
   },
   "source": [
    "The tenures are grouped into categories. The churn rate across these tenure groups will be examined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "dMQUSQI4CJRU",
    "outputId": "0e32c7a9-af96-4730-e200-6a040dfd7220"
   },
   "outputs": [],
   "source": [
    "# Calculate the number of customers, the percentage of customers, and the churn rate for each tenure\n",
    "customers_per_tenure = train['TENURE'].value_counts()\n",
    "percentage_customers_per_tenure = ((customers_per_tenure / customers_per_tenure.sum()) * 100).round(2)\n",
    "churn_rate_by_tenure = (train.groupby('TENURE')['CHURN'].mean()).round(2) # 2 decimal places where used in both to properly display the results\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "tenure_group_data = pd.DataFrame({\n",
    "    'Number of Customers': customers_per_tenure,\n",
    "    'Percentage of Customers (%)': percentage_customers_per_tenure,\n",
    "    'Churn Rate (%)': churn_rate_by_tenure\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "tenure_group_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMnINggKTBpS"
   },
   "source": [
    "As shown above, 94.88% of the customers have been with the network for 24 months and above (that is, 2 years and above). The churn rate among this group of customers is 0.18%, which is relatively low. The highest churn rate is 0.32% and it is observed for customers within 12-15 months duration. After one year with the network, these customers churned (became inactive for 90 days). Promotional activities such as one-year bonanza may help to retain these set of customers on the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "P1YzT_duVvRa",
    "outputId": "7cf20303-53ce-4d45-b0b4-2a24b254143d"
   },
   "outputs": [],
   "source": [
    "# Plot a bar chart for the churn rate by tenure\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 2)\n",
    "tenure_group_data['Churn Rate (%)'].plot(kind='bar')\n",
    "plt.title(\"Churn Rate by Tenure\")\n",
    "plt.xlabel(\"Tenure\")\n",
    "plt.ylabel(\"Churn Rate (%)\")\n",
    "plt.xticks(rotation=65)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot into the drive through the image_path\n",
    "file_name = 'Churn Rate by Tenure.png'\n",
    "file_path = os.path.join(image_path, file_name)\n",
    "plt.savefig(file_path)\n",
    "\n",
    "# Display the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXlx4Alw4sa4"
   },
   "source": [
    "# Feature Engineering\n",
    "\n",
    "\n",
    "Feature engineering is the process of creating new, meaningful, and informative features (variables) from the existing data to improve the performance of machine learning models. It involves creating, selecting, or transforming features that help models better understand patterns, relationships, and trends within the data.\n",
    "\n",
    "Effective feature engineering can lead to more accurate and efficient models because the process would provide relevant data with reduced noise, which would enhance the predictive power of the data.\n",
    "\n",
    "Feature engineering requires domain knowledge and creativity to extract valuable insights and knowledge from the raw data, which can significantly impact the success of machine learning projects.\n",
    "\n",
    "The feature engineering techniques that will be used in this project are: feature selection, data sampling, feature extraction, data splitting, feature scaling and feature encoding. These techniques will enhance the modelling process.\n",
    "\n",
    "Since changes will be made on the train and test datasets during the feature engineering processes, copies of these datasets will first be made for future usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d1tHYpKjrLSR"
   },
   "outputs": [],
   "source": [
    "# Make copies of the train and test datasets before commencing the features engineering processes\n",
    "\n",
    "train_data = train.copy()\n",
    "test_data = test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nWRC3pDL482S"
   },
   "source": [
    "## Feature Selection\n",
    "\n",
    "This is a feature engineering process that is used to choose the desired columns (columns that are relevant to the modelling) for further processing. This means that some of the columns of the train dataset will be dropped at this point, leaving only the relevant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OzQhYhJBbfn8",
    "outputId": "604bdb16-3857-4457-a044-bf6e5ff98992"
   },
   "outputs": [],
   "source": [
    "# List the columns in the train dataset\n",
    "\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "oqOzN_j8bfn9",
    "outputId": "3e346d10-5561-4851-c476-7fb4c36ab15f"
   },
   "outputs": [],
   "source": [
    "# Identify the columns to drop\n",
    "columns_to_drop = ['user_id', 'REGION', 'ZONE1', 'ZONE2', 'MRG', 'TOP_PACK']\n",
    "\n",
    "# Drop these columns in the train dataset using the \"drop()\" method\n",
    "train.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "_jYFW36Lbfn-",
    "outputId": "68e683aa-9e80-4c02-c28d-1294dcc64e2a"
   },
   "outputs": [],
   "source": [
    "# Drop these columns in the test datast using the \"drop()\" method\n",
    "\n",
    "test.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5wQTRallfmj"
   },
   "source": [
    "## Data Sampling\n",
    "\n",
    "Large datasets can be computationally expensive and time-consuming to work with. Data sampling is a technique used to create a smaller, representative subset of the data for model development and testing. This can make the modeling process more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1K-tDmfbKImX",
    "outputId": "4299b787-1455-426e-90de-83b9e231bdc6"
   },
   "outputs": [],
   "source": [
    "# Check the shape of the train dataset\n",
    "\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GXMSnwyrJzrn"
   },
   "source": [
    "Since the train dataset is very large (with 1,077,024 rows), a subset of the data would be used to train the models in order to adequately manage time and available computational resources.\n",
    "\n",
    "There are many rows with missing values across the columns of the train dataset. This is as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lLG_Iu-bxMwI",
    "outputId": "69d2f45f-071a-48b3-99d7-c2a6137613d3"
   },
   "outputs": [],
   "source": [
    "# identify the columns with missing values on the train dataset\n",
    "\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "id": "pMs3nr6UhdDl",
    "outputId": "b744a6a1-682a-44c3-bef5-52f6320ab701"
   },
   "outputs": [],
   "source": [
    "# Calculate the percentage of missing values for each column on the train dataset\n",
    "train_missing_percentage = (train.isnull().mean() * 100).round(2)\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "train_missing_percentage_df = pd.DataFrame({'Missing Percentage (%)': train_missing_percentage})\n",
    "\n",
    "# Display the DataFrame\n",
    "train_missing_percentage_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D-Cr0gBZ-l_5"
   },
   "source": [
    "A great percentage of rows across the columns of the train dataset have missing values, filling them by imputation would introduce some bias to the dataset. Dropping these rows would be a better decision. This will also help to generate a subset of the train dataset which would optimize the modelling process.\n",
    "\n",
    "'DATA_VOLUME', 'TIGO', 'ORANGE', and 'FREQ_TOP_PACK' are the columns with the highest percentage of missing values in the train dataset. The rows with missing values across these columns will be dropped to achieve manual data sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rlQ0N84XhdmK"
   },
   "outputs": [],
   "source": [
    "# Create a variable for the columns with high missing values\n",
    "\n",
    "columns_with_high_missing_values = ['DATA_VOLUME', 'TIGO', 'ORANGE', 'FREQ_TOP_PACK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tnCtkmOK79mZ",
    "outputId": "c37eae28-3a11-4442-d1f7-94a718dc192c"
   },
   "outputs": [],
   "source": [
    "# Drop the rows with missing values across these columns in train dataset\n",
    "train = train.dropna(subset=columns_with_high_missing_values)\n",
    "\n",
    "# Verify that there are very little missing values\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebc12GYXxk3t"
   },
   "source": [
    "As can be seen above, there are now fewer rows with missing values across the columns of the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "id": "Ph4D5v7kwxLG",
    "outputId": "1440d968-eaad-4555-b717-ed2fc0e7ff77"
   },
   "outputs": [],
   "source": [
    "# Recheck the percentage of missing values for each column on the train dataset\n",
    "\n",
    "train_missing_percentage = (train.isnull().mean() * 100).round(2)\n",
    "train_missing_percentage_df = pd.DataFrame({'Missing Percentage (%)': train_missing_percentage})\n",
    "train_missing_percentage_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1INYfYeBWB6"
   },
   "source": [
    "The percentage of missing values across the columns of the train dataset has greatly reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IVVObTtGBKt6",
    "outputId": "006bf54e-f1a6-4216-9641-318a5abe5113"
   },
   "outputs": [],
   "source": [
    "# Check the shape of the train dataset\n",
    "\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KiDY3KboBjy_"
   },
   "source": [
    "A reasonable subset of the train datset has been obtained which will help in managing available time, as well as computational resources for the modelling process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njS0hErm0BMr"
   },
   "source": [
    "The manual data sampling technique (dropping of some rows with missing values) achieved the following results:\n",
    "- The percentage of rows with missing values reduced across the columns. This would ensure that filling the remaining few missing values by imputation will not introduce significant bias to the dataset.\n",
    "- The number of rows in the train dataset reduced, giving a reasonable subset that is still suitable for the modelling process. This would ensure that available time and computational resources are well-managed.\n",
    "\n",
    "**Next steps for handling missing values:**\n",
    "- The remaining missing values in the train dataset will be handled by imputation.\n",
    "- All the missing values in the test dataset will also be handled by imputation. Rows with missing values in the test dataset will not be dropped in order to maintain the number of rows in the dataset, as each row represents a seperate user whose churn prediction is expected.\n",
    "\n",
    "**Note:** The imputation described above will be done after the feature extraction and data splitting processes to generate the training set and validation set. This means that the training and validation sets will be imputed seperately. Imputing them seperately will avoid the possiblility of data leakage, which can reduce the effectiveness of the validation set. The validation set is an important component for model evaluation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMd2fwPr6Jl-"
   },
   "source": [
    "## Feature Extraction\n",
    "\n",
    "Feature extraction transforms data into a reduced set of relevant and informative features, which can be more meaningful and suitable for use in Data Analysis and Machine Learning tasks, making it easier for Machine Learning algorithms to learn and make accurate predictions or classifications.\n",
    "\n",
    "The feature extraction technique used in this project aims to obtain the features (X) and target (y) variables of the train dataset, before splitting the dataset to obtain the training set and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sjnT_z9sbfoF",
    "outputId": "3e8abfa1-34b7-4782-dead-c1b2878a19ea"
   },
   "outputs": [],
   "source": [
    "# Obtain the features (X) and target (y) variables on the train dataset\n",
    "y = train['CHURN']\n",
    "X = train.drop(columns=['CHURN'], axis=1)\n",
    "\n",
    "# Print the shape of the features\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MpR2q9ss6ZcC"
   },
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BBNX2HxMbfoH",
    "outputId": "2e7abcf1-e3b0-4617-ef08-bdade4b12a82"
   },
   "outputs": [],
   "source": [
    "# Split the features(X) and target(y) variables to obtain the training and validation sets\n",
    "X_train,X_val,y_train,y_val = train_test_split(X,y,test_size=0.5,random_state=42)\n",
    "\n",
    "# Print the shape of the training and validation sets\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txZAjGpT0srx"
   },
   "source": [
    "## Imputation\n",
    "\n",
    "Imputation is the process of filling in missing values in a dataset with estimated or calculated values. It is typically done to ensure that the dataset is complete and can be used for various data analysis and machine learning tasks. Common imputation strategies include filling missing values with the mean, median, mode, or other statistical measures.\n",
    "\n",
    "Since the columns with missing values are numeric columns and the percentage of missing values are now relatively small, a SimpleImputer with strategy set to 'mean' will be used to fill the missing values. The training set, validation set, and test dataset will be fitted to the imputer and transformed seperately to avoid data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLEPm4A32xq8"
   },
   "outputs": [],
   "source": [
    "# Initialize the imputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "roSyhymc20db"
   },
   "outputs": [],
   "source": [
    "# Specify all the numeric columns\n",
    "\n",
    "num_cols = ['MONTANT', 'FREQUENCE_RECH', 'REVENUE', 'ARPU_SEGMENT', 'FREQUENCE', 'DATA_VOLUME', 'ON_NET', 'ORANGE', 'TIGO',\n",
    "            'REGULARITY', 'FREQ_TOP_PACK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IF30v6h50tJH",
    "outputId": "65806f18-9619-4a16-db2c-2b98ea54706a"
   },
   "outputs": [],
   "source": [
    "# Fit and transform the numerical columns of the training set\n",
    "X_train[num_cols] = imputer.fit_transform(X_train[num_cols])\n",
    "\n",
    "# Verify that the training set has been transformed by the imputer\n",
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uz6aZkpU2hu_",
    "outputId": "577676b3-8071-4edc-c86f-d7ea97c228ef"
   },
   "outputs": [],
   "source": [
    "# Fit and transform the numerical columns of the validation set\n",
    "X_val[num_cols] = imputer.fit_transform(X_val[num_cols])\n",
    "\n",
    "# Verify that the validation set has been transformed by the imputer\n",
    "X_val.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rwPQhwGI6i3H",
    "outputId": "e413ed86-9e47-4e07-b808-44dca59ae686"
   },
   "outputs": [],
   "source": [
    "# Fit and transform the numerical columns of the test dataset\n",
    "test[num_cols] = imputer.fit_transform(test[num_cols])\n",
    "\n",
    "# Verify that the test dataset has been transformed by the imputer\n",
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-cCmFtInL3bp"
   },
   "source": [
    "## Feature Scaling\n",
    "\n",
    "Scaling is the process of transforming numerical features in a dataset to have a common scale or range. It is important when the numerical features have different units or magnitudes, as some machine learning algorithms are sensitive to feature scales. StandardScaler (z-score normalization) and Min-MaxScaler are common methods to scale features to a similar range.\n",
    "\n",
    "For this project, StandardScaler will be used because of it's robustness and compatibility with a wide range of Machine Learning models. The training set, validation set, and test dataset will be fitted to the scaler and transformed seperately to avoid data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WiQWJ2qfbfoT"
   },
   "outputs": [],
   "source": [
    "# Initialize the scaler\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "1Fxz64BKbfoT",
    "outputId": "444fcd3c-6f9e-497e-f34f-bff47e74f7f2"
   },
   "outputs": [],
   "source": [
    "# Fit and transform the numerical columns of training set\n",
    "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "\n",
    "# Verify that the numerical columns of training set have been transformed by the scaler\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "BClEh-XGbfoU",
    "outputId": "6bb163a6-10f1-4f99-8b86-c4f9a25eaa19"
   },
   "outputs": [],
   "source": [
    "# Fit and transform the numerical columns of validation set\n",
    "X_val[num_cols] = scaler.fit_transform(X_val[num_cols])\n",
    "\n",
    "# Verify that the numerical columns of validation set have been transformed by the scaler\n",
    "X_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "5e3dqeyBbfoV",
    "outputId": "0e32a985-1e6a-4893-ebb9-f9b9a99a26ad"
   },
   "outputs": [],
   "source": [
    "# Fit and transform the numerical columns of test data\n",
    "test[num_cols] = scaler.fit_transform(test[num_cols])\n",
    "\n",
    "# Verify that the numerical columns of test data have been transformed by the scaler\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xYwA2VbOz_f"
   },
   "source": [
    "## Feature Encoding\n",
    "\n",
    "Encoding is the process of converting categorical (non-numeric) variables into a numerical format, which is suitable for machine learning algorithms. Categorical variables cannot be used directly by most Machine Learning models, so they need to be encoded into numerical representations.\n",
    "OneHotEncoder, LabelEncoder, and BinaryEncoder are commonly used for encoding categorical variables.\n",
    "\n",
    "Since the dataset for this project is considerably large, LabelEncoder will be used for its simplicity and memory-efficiency. The training set, validation set, and test dataset will be fitted to the encoder and transformed seperately to avoid data leakage.\n",
    "\n",
    "Note that the only categorical column on the datasets is the 'TENURE' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jT6FqxhubfoX"
   },
   "outputs": [],
   "source": [
    "# Initialize the encoder\n",
    "\n",
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "odszQWbXPNpd",
    "outputId": "55b2939d-dc95-4a48-8741-7eb422e4e7d0"
   },
   "outputs": [],
   "source": [
    "# Fit and transform the 'TENURE' column of training set\n",
    "X_train['TENURE'] = encoder.fit_transform(X_train['TENURE'])\n",
    "\n",
    "# Verify that the 'TENURE' column of training set has been transformed by the encoder\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "id": "WLtwWbH3bfoY",
    "outputId": "27f9dfe8-c7e0-459d-df12-57de20f28ce0"
   },
   "outputs": [],
   "source": [
    "# Fit and transform the 'TENURE' column of validation set\n",
    "X_val['TENURE'] = encoder.fit_transform(X_val['TENURE'])\n",
    "\n",
    "# Verify that the 'TENURE' column of validation set has been transformed by the encoder\n",
    "X_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "aEWnYrujbfoY",
    "outputId": "a7796963-e6ec-4959-e9b1-60b0445d136d"
   },
   "outputs": [],
   "source": [
    "# Fit and transform the 'TENURE' column of test data\n",
    "test['TENURE'] = encoder.fit_transform(test['TENURE'])\n",
    "\n",
    "# Verify that the 'TENURE' column of test data has been transformed by the encoder\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lv24AprjRxHp"
   },
   "source": [
    "## Class Balancing\n",
    "\n",
    "Class balancing aims to address the issue of class imbalance, where one class has significantly fewer samples compared to the other class. Techniques for class balancing include oversampling the minority class, undersampling the majority class, or a combination of both to create a balanced training set. Balancing the classes is essential to avoid model bias and ensure that the Machine Learning models can effectively learn from the available data.\n",
    "\n",
    "For this project, there is an imbalance in the predictor class (target variable) of the training set. This imbalance will be handled by oversampling the minority class and undersampling the majority class as shown below. The Synthetic Minority Over-sampling Technique (SMOTE) and the RandomUnderSampler will be used respectively to achieve this. These techniques are preferred as this project involves binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "008-xGoiuP8J",
    "outputId": "9fbc7463-76bc-4489-a99d-7924a004029e"
   },
   "outputs": [],
   "source": [
    "# Perform oversampling using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_oversampled, y_train_oversampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Perform undersampling using RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_balanced, y_train_balanced = rus.fit_resample(X_train_oversampled, y_train_oversampled)\n",
    "\n",
    "# Print the class distribution before and after balancing\n",
    "print(\"Before balancing:\")\n",
    "print(y_train.value_counts())\n",
    "print(\"\\nAfter balancing:\")\n",
    "print(pd.Series(y_train_balanced).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bvsrorXqRHOf"
   },
   "source": [
    "# Modelling and Evaluation\n",
    "\n",
    "Modelling refers to the process of selecting and training a mathematical or computational representation of a real-world phenomenon. This representation is designed to capture the essential relationships, patterns, and behaviors observed in data. The primary goal of modeling is to make predictions, gain insights, or simulate the behavior of the real-world system, which may be too complex or difficult to analyze directly. There are different models for Machine Learning processes. The choice of modeling technique and the specific steps involved can vary greatly depending on the problem domain and the available data. The ultimate goal of modeling is to generate data-driven insights and use them to solve problems or make informed decisions.\n",
    "\n",
    "The models to be used for this project are:\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "- Gradient Boosting\n",
    "- Adaptive Boosting\n",
    "- Support Vector Machine\n",
    "- Gaussian Naive Bayes\n",
    "\n",
    "These models will be trained on the imbalanced training set, and the balanced training set to determine which set is giving better results. The results of each training process is measured by evaluating the performance of the models on the respective validation sets with the use of performance metrics.\n",
    "\n",
    "Performance metrics are the measures or criteria used to evaluate the performance/effectiveness of a machine learning model. The performance of the models above will be evaluated with the following performance metrics:\n",
    "- Accuracy: Accuracy measures the overall correctness of a model's predictions by calculating the ratio of correctly predicted instances (both true positives and true negatives) to the total number of instances in the dataset. It is useful when all classes have similar importance and the class distribution is balanced. It can be misleading in imbalanced datasets.\n",
    "- Precision: Precision assesses the ability of a model to correctly identify positive instances among all instances it predicts as positive. It is the ratio of true positives to the total number of instances predicted as positive. Precision is important when the cost of false positives (Type I errors) is high, and you want to minimize the rate of false alarms.\n",
    "- Recall (Sensitivity or True Positive Rate): Recall evaluates the model's ability to capture all positive instances in the dataset. It is the ratio of true positives to the total number of actual positive instances. Recall is crucial when the cost of false negatives (Type II errors) is high, and you want to minimize the rate of missed positive cases.\n",
    "- F1 Score: The F1 score is a balanced metric that combines Precision and Recall into a single value. It is the harmonic mean of Precision and Recall. A higher F1 score indicates a better balance between Precision and Recall. F1 score is useful when you want a single metric that considers both false positives and false negatives. It's particularly relevant when class distribution is imbalanced.\n",
    "- Area Under the Curve (AUC): AUC measures the ability of a model to discriminate between positive and negative instances across different probability thresholds. It is often used in the context of receiver operating characteristic (ROC) curves. A higher AUC indicates a better ability to rank positive instances higher than negative instances. AUC is valuable for evaluating the overall quality of a binary classifier. It's especially useful when the dataset may have class imbalance or when you need to compare the performance of different models.\n",
    "\n",
    "**The primary evaluation metric is Area Under the Curve (AUC).**\n",
    "\n",
    "The models will be tuned to optimize their performance, then trained and evaluated again to observe if the performance metrics improved. The results of the performance metrics for each training process will be stored in a DataFrame for easy comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RU31DrRwbfoZ"
   },
   "outputs": [],
   "source": [
    "# Create a list of models to train and evaluate\n",
    "\n",
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression(random_state=42, solver='lbfgs')),\n",
    "    ('Random Forest', RandomForestClassifier(bootstrap=True, criterion=\"gini\", n_jobs=-1)),\n",
    "    ('Gradient Boosting', GradientBoostingClassifier(random_state=42, n_estimators=50, subsample=1.0)),\n",
    "    ('Adaptive Boosting', AdaBoostClassifier(random_state=42, n_estimators=50, learning_rate=1.0)),\n",
    "    ('Support Vector Machine', SVC(random_state=42, C=1.0)),\n",
    "    ('Gaussian Naive Bayes', GaussianNB())\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2HwGGzFkT8l"
   },
   "source": [
    "## Model training and evaluation with imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-iR6EdPIJBUm"
   },
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store the performance metrics of the models after training with imbalanced dataset\n",
    "imbal_performance_metrics = {}\n",
    "\n",
    "# Model training, evaluation and result calculation\n",
    "for model_name, model in models:\n",
    "    # Model training with imbalanced dataset\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Using the models to make predictions on the validation set\n",
    "    y_pred_imbal = model.predict(X_val)\n",
    "\n",
    "    # Calculate the performance metrics of the models on the imbalanced dataset\n",
    "    accuracy = accuracy_score(y_val, y_pred_imbal)\n",
    "    precision = precision_score(y_val, y_pred_imbal)\n",
    "    recall = recall_score(y_val, y_pred_imbal)\n",
    "    f1 = f1_score(y_val, y_pred_imbal)\n",
    "    auc = roc_auc_score(y_val, y_pred_imbal)\n",
    "\n",
    "    # Store the performance metrics results\n",
    "    imbal_performance_metrics[model_name] = {\n",
    "        'Imbal Accuracy': accuracy,\n",
    "        'Imbal Precision': precision,\n",
    "        'Imbal Recall': recall,\n",
    "        'Imbal F1 Score': f1,\n",
    "        'Imbal AUC': auc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "xRWdKDnOIdB2",
    "outputId": "b057dd69-2666-4366-e194-1923b6110dfb"
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame to store the performance metrics of the models on the imbalanced dataset\n",
    "imbalanced_performance_metrics = pd.DataFrame(imbal_performance_metrics).transpose()\n",
    "\n",
    "# Arrange the performance metrics DataFrame in descending order based on the AUC score\n",
    "imbalanced_performance_metrics = imbalanced_performance_metrics.sort_values('Imbal AUC', ascending=False)\n",
    "\n",
    "# Show the performance metrics DataFrame of the models on the imbalanced dataset\n",
    "imbalanced_performance_metrics.style.set_caption('The Performance Metrics Of The Models On The Imbalanced Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhIGQ9ietTlE"
   },
   "source": [
    "From the Performance Metric DataFrame above, the best performing model on the imbalanced train dataset is the Gaussian Naive Bayes with an AUC score of 0.722989. Observe that this model also has the highest Recall score (0.711884) and the second highest F1 score (0.120612), but the lowest Accuracy score (0.733524) and one of the lowest Precision scores (0.065888). Here are the implications of these observations:\n",
    "\n",
    "- High AUC Score: A high AUC score (0.722989) indicates that the Gaussian Naive Bayes model performs well in terms of distinguishing between the two classes (positive and negative). It means the model has a good ability to rank positive instances higher than negative ones.\n",
    "\n",
    "- High Recall Score: The high Recall score (0.711884) suggests that the Gaussian Naive Bayes model has a low rate of false negatives. It correctly identifies a significant portion of the actual positive cases. In the context of binary classification, this is important when there is need to minimize the number of positive cases that are missed.\n",
    "\n",
    "- Low Accuracy Score: The low Accuracy score (0.733524) indicates that the model doesn't perform well in terms of overall correct predictions. Accuracy alone is not the best metric for imbalanced datasets, especially when there is a significant class imbalance. In this case, the model's imbalance could be contributing to the low accuracy.\n",
    "\n",
    "- Low Precision Score: The low Precision score (0.065888) suggests that the model has a high rate of false positives. It means that when the model predicts a positive case, it's often incorrect. This is reflected in the low precision score, which is calculated as the ratio of true positives to the total predicted positives.\n",
    "\n",
    "- Second-Highest F1 Score: The second-highest F1 score (0.120612) indicates that the model achieves a balance between precision and recall. The F1 score is the harmonic mean of precision and recall, and it is often used when there is an imbalance between the classes. The Gaussian Naive Bayes model has a relatively good F1 score, although it's not the highest among the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0Gr2qwqkbyu"
   },
   "source": [
    "## Model training and evaluation with balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Ti3UONRkd_5"
   },
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store the performance metrics of the models after training with balanced dataset\n",
    "bal_performance_metrics = {}\n",
    "\n",
    "# Model training, evaluation and result calculation\n",
    "for model_name, model in models:\n",
    "    # Model training with balanced dataset\n",
    "    model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "    # Using the models to make predictions on the validation set\n",
    "    y_pred_bal = model.predict(X_val)\n",
    "\n",
    "    # Calculate the performance metrics of the models on the balanced dataset\n",
    "    accuracy = accuracy_score(y_val, y_pred_bal)\n",
    "    precision = precision_score(y_val, y_pred_bal)\n",
    "    recall = recall_score(y_val, y_pred_bal)\n",
    "    f1 = f1_score(y_val, y_pred_bal)\n",
    "    auc = roc_auc_score(y_val, y_pred_bal)\n",
    "\n",
    "    # Store the performance metrics results\n",
    "    bal_performance_metrics[model_name] = {\n",
    "        'Bal Accuracy': accuracy,\n",
    "        'Bal Precision': precision,\n",
    "        'Bal Recall': recall,\n",
    "        'Bal F1 Score': f1,\n",
    "        'Bal AUC': auc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f4PSvqG_keTo"
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame to store the performance metrics of the models on the balanced dataset\n",
    "balanced_performance_metrics = pd.DataFrame(bal_performance_metrics).transpose()\n",
    "\n",
    "# Arrange the performance metrics DataFrame in descending order based on the AUC score\n",
    "balanced_performance_metrics = balanced_performance_metrics.sort_values('Bal AUC', ascending=False)\n",
    "\n",
    "# Show the performance metrics DataFrame of the models on the balanced dataset\n",
    "balanced_performance_metrics.style.set_caption('The Performance Metrics Of The Models On The Balanced Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsJO8hrRPypn"
   },
   "source": [
    "From the Performance Metric DataFrame above, the best performing model on the balanced train dataset based on AUC score is the Support Vector Machine as it has the highest AUC score (0.773081). While the Gaussian Naive Bayes that had the best AUC score on the imbalanced dataset (0.722989) now has the worst AUC score on the balanced dataset (0.628601). Also observe that the Support Vector Machine has the highest Accuracy score (0.783825), the highest Precision score (0.085163), the highest F1 score (0.153198), and a moderate Recall score (0.761755) on the balanced dataset. Here are the implications of these observations on Support Vector Machine (SVM):\n",
    "\n",
    "High AUC Score (0.773081): A high AUC (Area Under the Curve) score indicates that the SVM model has a strong ability to distinguish between the positive and negative classes. This suggests that the model's predictions and the actual target values are well separated, which is a positive sign for the model's overall performance.\n",
    "\n",
    "High Accuracy Score (0.783825): The high accuracy score indicates that the SVM model makes a high proportion of correct predictions on the balanced dataset. This suggests that the model is effective in classifying both positive and negative cases.\n",
    "\n",
    "High Precision Score (0.085163): Precision measures the ratio of true positive predictions to all positive predictions made by the model. The high precision score indicates that when the SVM model predicts the positive class (that is, \"1\" meaning \"CHURN\"), it is accurate in doing so. In other words, it has a low rate of false positives.\n",
    "\n",
    "High F1 Score (0.153198): The F1 score is the harmonic mean of precision and recall. A high F1 score indicates a balance between precision and recall. In this case, the SVM model achieves a good trade-off between identifying true positives and minimizing false positives.\n",
    "\n",
    "Moderate Recall Score (0.761755): Recall measures the ratio of true positive predictions to all actual positive cases. While the SVM model's recall score is not the highest, it is still reasonably good. The model is effective in identifying most of the actual positive cases, although there is some room for improvement.\n",
    "\n",
    "The performance of the models on the imbalanced and balanced datasets will be compared by concatenating the DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sP5FRMTylhy2"
   },
   "outputs": [],
   "source": [
    "# Concatenate the performance metrics DataFrames for the imbalanced and balanced datasets while preserving columns\n",
    "cocatenate_performance_metrics = pd.concat([imbalanced_performance_metrics, balanced_performance_metrics], axis=1)\n",
    "\n",
    "# Arrange the combined performance metrics DataFrame in descending order based on the AUC score for the balanced dataset\n",
    "cocatenate_performance_metrics = cocatenate_performance_metrics.sort_values('Bal AUC', ascending=False)\n",
    "\n",
    "# Show the DataFrame\n",
    "cocatenate_performance_metrics.style.set_caption('The Performance Metrics Of The Models On The Imbalanced And Balanced Datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2fZEqFF2XhzG"
   },
   "source": [
    "As can be seen above, there is significant improvement on the AUC score of each model on the balanced dataset in comparison to the imbalanced dataset, with an exception for Gaussian Naive Bayes whose AUC score dropped on the balanced dataset. Notwithstanding, the AUC Score of Support Vector Machine on the balanced dataset (0.773081) is still higher than that of Gaussian Naive Bayes on the imbalanced dataset (0.722989). These observations imply that the models generally performed better on the balanced dataset.\n",
    "\n",
    "Since Support Vector Machine and Logistic Regression performed very well on the balanced dataset compared to the other models, with an AUC Score of 0.773081 and 0.769256 respectively, these two models will be passed through hyperparameter tuning. After performing hyperparameter tuning on these models, they will be trained again on the balanced dataset to see if their performance will improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oatAoxgeEjvh"
   },
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "Hyperparameters are adjustable parameters whose values control the model training process.\n",
    "\n",
    "Hyperparameter tuning (or hyperparameter optimization) is a process used to determine the right combination of hyperparameters that maximizes the model performance. It works by running multiple trials on a model in a single training process. The parameters of the model are then set within specified limits and executed to identify the set of parameter values that give optimal results for the model.\n",
    "\n",
    "Of all the models trained on the balanced dataset, Support Vector Machine and Logistic Regression are the best performing models. These two models will be passed through hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BOCp8ekTEpM6"
   },
   "outputs": [],
   "source": [
    "# Create a list of models to pass through hyperparameter tuning\n",
    "\n",
    "hyperparameter_models = [\n",
    "    ('Logistic Regression', LogisticRegression(random_state=42, solver='lbfgs')),\n",
    "    ('Support Vector Machine', SVC(random_state=42, C=1.0))\n",
    "]\n",
    "\n",
    "# Get the available parameters for each model\n",
    "for model_name, model in hyperparameter_models:\n",
    "    available_params = model.get_params()\n",
    "    print(f'Available Parameters For {model_name}:{available_params}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HCWNsTI7E8My"
   },
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store the tuned models\n",
    "tuned_models = {}\n",
    "\n",
    "# Initialize a dictionary to store the performance metrics of the tuned models\n",
    "tun_performance_metrics = {}\n",
    "\n",
    "# Perform hyperparameter tuning within specified limits\n",
    "for model_name, model in hyperparameter_models:\n",
    "    params_selection = {\n",
    "        'Logistic Regression': {'solver': ['newton-cg', 'lbfgs', 'liblinear'], 'C': [100, 10, 1.0]},\n",
    "        'Support Vector Machine': {'kernel': ['poly', 'rbf', 'sigmoid'], 'C': [100, 10, 1.0]}\n",
    "    }\n",
    "\n",
    "    # Get the selected parameter values for the models to tune\n",
    "    param_grid = params_selection[model_name]\n",
    "\n",
    "    # Perform hyperparameter tuning using GridSearchCV\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='roc_auc', verbose=0, refit=True)\n",
    "    grid_search.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "    # Get the tuned models with their best parameters\n",
    "    best_params = grid_search.best_params_\n",
    "    tuned_model = grid_search.best_estimator_\n",
    "\n",
    "    # Store the tuned models\n",
    "    tuned_models[model_name] = tuned_model\n",
    "\n",
    "    # Show the best parameters for each tuned model\n",
    "    print(f'The best parameters for {model_name} are {best_params}\\n')\n",
    "\n",
    "    # Training each tuned model and making predictions on the validation set\n",
    "    tuned_model.fit(X_train_balanced, y_train_balanced)\n",
    "    y_pred_tun = tuned_model.predict(X_val)\n",
    "\n",
    "    # Calculate the performance metrics on the balanced dataset for each tuned model\n",
    "    accuracy = accuracy_score(y_val, y_pred_tun)\n",
    "    precision = precision_score(y_val, y_pred_tun)\n",
    "    recall = recall_score(y_val, y_pred_tun)\n",
    "    f1 = f1_score(y_val, y_pred_tun)\n",
    "    auc = roc_auc_score(y_val, y_pred_tun)\n",
    "\n",
    "    # Store the performance metrics results\n",
    "    tun_performance_metrics[model_name] = {\n",
    "        'Tuned Accuracy': accuracy,\n",
    "        'Tuned Precision': precision,\n",
    "        'Tuned Recall': recall,\n",
    "        'Tuned F1 Score': f1,\n",
    "        'Tuned AUC': auc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h6-xB7CKFcVg"
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame to store the performance metrics of the tuned models on the balanced dataset\n",
    "tuned_performance_metrics = pd.DataFrame(tun_performance_metrics).transpose()\n",
    "\n",
    "# Arrange the performance metrics DataFrame in descending order based on the AUC score of the tuned models\n",
    "tuned_performance_metrics = tuned_performance_metrics.sort_values('Tuned AUC', ascending=False)\n",
    "\n",
    "# Show the performance metrics DataFrame of the tuned models on the balanced dataset\n",
    "tuned_performance_metrics.style.set_caption('The Performance Metrics Of The Tuned Models On The Balanced Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91c6vYZbG7Fn"
   },
   "source": [
    "## Obtain the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wN5vnVHYG6Ok"
   },
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store the best models\n",
    "best_models = {}\n",
    "\n",
    "# Iterate through the models and their AUC scores\n",
    "for model_name, metrics in tun_performance_metrics.items():\n",
    "    auc_score = metrics['Tuned AUC']\n",
    "\n",
    "    # Update the best model in the dictionary if the current model has a higher AUC score\n",
    "    if not best_models or auc_score > best_auc_score:\n",
    "        best_auc_score = auc_score\n",
    "        best_model_name = model_name\n",
    "        best_model = tuned_models[model_name]\n",
    "\n",
    "# Display the best model_name with the highest AUC score\n",
    "print(f'The best model is {best_model_name} with an AUC score of {best_auc_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dsiFnunqpJP"
   },
   "source": [
    "## Confusion matrix of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kElX6jfzqtnQ"
   },
   "outputs": [],
   "source": [
    "# Make predictions on the validation set\n",
    "best_model_pred = best_model.predict(X_val)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "confusion = confusion_matrix(y_val, best_model_pred)\n",
    "confusion\n",
    "\n",
    "# Plot the confusion matrix using a heatmap\n",
    "sb.heatmap(confusion, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix of the Best Model')\n",
    "\n",
    "# Save the plot into the drive through the image_path\n",
    "file_name = 'Confusion Matrix of the Best Model.png'\n",
    "file_path = os.path.join(image_path, file_name)\n",
    "plt.savefig(file_path)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8ubSBiawGBd"
   },
   "source": [
    "## Precision-recall curve of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y3RALhtawPoy"
   },
   "outputs": [],
   "source": [
    "# Use the best model to predict probabilities\n",
    "y_scores = best_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Calculate precision and recall\n",
    "precision, recall, thresholds = precision_recall_curve(y_val, y_scores)\n",
    "\n",
    "# Print precision, recall, and thresholds\n",
    "for p, r, t in zip(precision, recall, thresholds):\n",
    "    print(f\"Precision: {p:.2f} | Recall: {r:.2f} | Threshold: {t:.2f}\")\n",
    "\n",
    "# Plot the precision-recall curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, color='b', lw=2, label='Precision-Recall curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.grid()\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# Save the plot into the drive through the image_path\n",
    "file_name = 'Precision-Recall Curve of the Best Model.png'\n",
    "file_path = os.path.join(image_path, file_name)\n",
    "plt.savefig(file_path)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JrwPXNtKZNYo"
   },
   "source": [
    "# Prediction on test dataset\n",
    "\n",
    "The best model will be used to make predictions on the test dataset in order to identify the customers at the risk of churning. This customer churn prediction on the test dataset will subsequently be used to fill the 'CHURN' column of the submission dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9EOY4S50ZdBT"
   },
   "outputs": [],
   "source": [
    "# Make predictions on the test dataset using the best model\n",
    "test_pred = best_model.predict(test_data)\n",
    "\n",
    "# Print the test dataset predictions\n",
    "test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USDUg1JpKbMQ"
   },
   "source": [
    "Remember that copies of the train and test datasets named \"train_data\" and \"test_data\" respectively were made before commencing the feature engineering processes. These copies contain all the original columns of each dataset. The \"test_data\" dataset is important at this stage as it contains the original 'user_id' column of \"test\" dataset.\n",
    "\n",
    "A 'CHURN' column will be created for the \"test_data\" dataset to store the churn prediction results of each customer for their respective user_ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oeiOw2ZBKbyi"
   },
   "outputs": [],
   "source": [
    "# Create a 'CHURN' column for the test_data dataset and fill it with the test dataset predictons\n",
    "\n",
    "test_data['CHURN'] = test_pred\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wCVgR3YWcfUo"
   },
   "source": [
    "# Submission\n",
    "\n",
    "The 'user_id' and 'CHURN' columns of the \"test_data\" dataset will be used to create a new dataset for submission named \"submission_data\"\n",
    "\n",
    "The \"submission_data\" dataset will then be saved into the \"Submission\" folder on the Google Drive. The path to this folder on the drive has been defined already (immediately after the drive was mounted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tuhqoOEbN27X"
   },
   "outputs": [],
   "source": [
    "# First display the the first five rows of \"submission_sample\" dataset\n",
    "\n",
    "submission_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kjh-bccVgmFD"
   },
   "outputs": [],
   "source": [
    "# Create the \"submission_data\" dataset\n",
    "submission_data = test_data[['user_id', 'CHURN']]\n",
    "\n",
    "# Display the first five rows of \"submission_data\" dataset\n",
    "submission_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "An0wJCU_bfoi"
   },
   "outputs": [],
   "source": [
    "# Save the \"submission_data\" as a CSV into the drive through the submission_path\n",
    "\n",
    "file_name = 'submission_data.csv'\n",
    "file_path = os.path.join(submission_path, file_name)\n",
    "submission_file.to_csv(file_path, index=False) # Set index to False as there is no index on the \"submission_sample\" dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23rjg4IhqqWF"
   },
   "source": [
    "# Exportation\n",
    "\n",
    "The key Machine Learning components which are the imputer, the scaler, the encoder, and the best model will be exported so that they can be re-used later. When exported, these Machine Learning components can be deployed into apps and APIs for wide-scale customer churn predictions.\n",
    "\n",
    "The exportation process begins with saving the Machine Learning components into a dictionary. This dictionary will be used to store these components into a picke file named \"ml_components.pkl\", which will then be saved into the \"Export\" folder on the Google Drive. The path to this folder on the drive has been defined already (immediately after the drive was mounted).\n",
    "\n",
    "Another file named \"requirements.txt\" will also be created. This file saves a list of installed Python packages and their versions used for this project. Creating this file is a convenient way to capture the virtual environment dependencies used to run this project, making it possible for these same virtual environment dependencies to be re-used in the future to make changes to this project, or run a similar project. The \"requirements.txt\" file will also be saved into the \"Export\" folder on the Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z-MRIxflqsD_"
   },
   "outputs": [],
   "source": [
    "# Create a dictionary to store all the Machine Learning components\n",
    "ml_components = {\n",
    "    'imputer': imputer,\n",
    "    'scaler': scaler,\n",
    "    'encoder': encoder,\n",
    "    'model': best_model\n",
    "}\n",
    "\n",
    "# Create a pickle file to store the Machine Learning components and save it into the drive\n",
    "with open(os.path.join(export_path, 'ml_components.pkl'), 'wb') as file:\n",
    "    pickle.dump(ml_components, file)\n",
    "\n",
    "# Create a requirements.txt file to capture the virtual environment and also save it into the drive\n",
    "os.system(f'pip freeze > {export_path}/requirements.txt')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
